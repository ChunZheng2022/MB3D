
# MB3D:Improving pseudo-point-based 3D object detection through modal balancing
This is a official code release of MB3D. 
This code is mainly based on [VirConv](https://arxiv.org/abs/2303.02314) and [OpenPCDet](https://github.com/open-mmlab/OpenPCDet), some codes are from [TED](https://github.com/hailanyi/TED), 
[CasA](https://github.com/hailanyi/CasA), [PENet](https://github.com/JUGGHM/PENet_ICRA2021) and [SFD](https://github.com/LittlePey/SFD).


## Getting Started
### Dependency
Our implementation is tested on.

+ Ubuntu 22.04
+ Python 3.8.17
+ PyTorch 1.10.1
+ Numba 0.53.1
+ Spconv 2.1.25 # pip install spconv-cu111
+ NVIDIA CUDA 11.1 
+ 8x Nvidia RTX 4090 GPUs for test set 
+ one RTX 3090 GPU for val set


### Prepare dataset

You shall creat additional ```velodyne_depth``` dataset to run our multimodal and semi-supervised detectors.

* You can download all the preprocessed data from
[baidu (mb3d)](https://pan.baidu.com/s/1z4Lgn4vD9Ui-0ZPignYWsQ?pwd=mb3d) \[74GB\]. The data is generated by [VirConv](https://arxiv.org/abs/2303.02314).
The ```semi``` dataset is not used in our work.

* Or you can generate the dataset by yourself as follows:

Please download the official [KITTI 3D object detection](http://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=3d) 
dataset and organize the downloaded files as follows (the road planes could be downloaded 
from [[road plane]](https://drive.google.com/file/d/1d5mq0RXRnvHPVeKx6Q612z0YRO1t2wAp/view?usp=sharing), 
which are optional for data augmentation in the training):

```
MB3D
├── data
│   ├── kitti
│   │   │── ImageSets
│   │   │── training
│   │   │   ├──calib & velodyne & label_2 & image_2 & (optional: planes)
│   │   │── testing
│   │   │   ├──calib & velodyne & image_2
├── pcdet
├── tools
```

(1) Download the PENet depth completion model from [google (500M)](https://drive.google.com/file/d/1RDdKlKJcas-G5OA49x8OoqcUDiYYZgeM/view?usp=sharing) or [baidu (gp68)](https://pan.baidu.com/s/1tBVuqvBZ0ns79ARmNpgwWw), and put it into ```tools/PENet```.

(2) Then run the following code to generate RGB pseudo points.

```
cd tools/PENet
python3 main.py --detpath ../../data/kitti/training
python3 main.py --detpath ../../data/kitti/testing
```
(3) After that, run following command to creat dataset infos:
```
python3 -m pcdet.datasets.kitti.kitti_dataset_mm create_kitti_infos tools/cfgs/dataset_configs/kitti_dataset.yaml
```
Anyway, the data structure should be: 
```
MB3D
├── data
│   ├── kitti
│   │   │── ImageSets
│   │   │── training
│   │   │   ├──calib & velodyne & label_2 & image_2 & (optional: planes) & velodyne_depth
│   │   │── testing
│   │   │   ├──calib & velodyne & image_2 & velodyne_depth
│   │   │── gt_database_mm
│   │   │── kitti_dbinfos_trainsemi.pkl
│   │   │── kitti_dbinfos_train_mm.pkl
│   │   │── kitti_infos_test.pkl
│   │   │── kitti_infos_train.pkl
│   │   │── kitti_infos_trainsemi.pkl
│   │   │── kitti_infos_trainval.pkl
│   │   │── kitti_infos_val.pkl
├── pcdet
├── tools
```

### Setup

```
cd MB3D
python setup.py develop
```

### Training.

Single GPU train:
```
cd tools
python3 train.py --cfg_file cfgs/kitti_models/MB3D.yaml
```

Multiple GPU train: 

You can modify the gpu number in the dist_train.sh and run
```
cd tools
sh dist_train.sh
```
The log infos are saved into log.txt
You can run ```cat log.txt``` to view the training process.

### Evaluation.

Single GPU test:

```
cd tools
python3 test.py --cfg_file cfgs/kitti_models/MB3D.yaml --ckpt checkpoint_epoch_90.pth
```

Multiple GPU test: you should modify the gpu number in the dist_test.sh and run
```
sh dist_test.sh 
```
The log infos are saved into log-test.txt
You can run ```cat log-test.txt``` to view the test results.
## License

This code is released under the [Apache 2.0 license](LICENSE).

## Acknowledgement
[VirConv](https://arxiv.org/abs/2303.02314)

[TED](https://github.com/hailanyi/TED)

[CasA](https://github.com/hailanyi/CasA)

[OpenPCDet](https://github.com/open-mmlab/OpenPCDet)

[PENet](https://github.com/JUGGHM/PENet_ICRA2021)

[SFD](https://github.com/LittlePey/SFD)




